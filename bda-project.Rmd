---
title: "project"
author: "anon"
date: "11/22/2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(aaltobda)
library(rstan)
library(loo)
library(latex2exp)
library(bayesplot)
rstan_options (javascript = FALSE)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

# R and Stan Code


```{r}
list.files()
```

```{r}
findings_df <- read.csv("findings.tsv_type.csv")
findings_df$journal = "findings"
head(findings_df)

main_df <- read.csv("main.tsv_type.csv")
main_df$journal = "main"
head(main_df)
```

```{r}
dim(main_df)
dim(findings_df)
data <- rbind(main_df, findings_df)

ggplot(data, aes(Citation, color=journal, fill=journal)) +
  geom_density(alpha=0.2) +
  coord_cartesian(xlim=c(0, 50))
```

# Analyze the distribution of citations across long / short papers

```{r}
long_papers = subset(data, type == "long")[, "Citation"]
short_papers = subset(data, type == "short")[, "Citation"]

median(short_papers)
mean(short_papers)
median(long_papers)
mean(long_papers)

#sampled_long_papers = sample(long_papers, size=length(short_papers))
hist_long = density(long_papers)
hist_short = density(short_papers)
plot(hist_long, col=rgb(0,0,1,1/4), xlim=c(0,30), ylim=c(0, 0.12), main="Citations by paper length", xlab="Number of citations")  # first histogram
polygon(hist_long, col=rgb(0,0,1,1/4), border=rgb(0,0,1,1/4)) 
lines(hist_short, col=rgb(1,0,0,1/4), xlim=c(0,30))  # second
polygon(hist_short, col=rgb(1,0,0,1/4), border=rgb(1,0,0,1/4)) 
legend("topright", legend=c("Long Papers", "Short Papers"), col=c(rgb(0,0,1,1/4), rgb(1,0,0,1/4)), lty=1:1, cex=0.8)
```
## Closed form solutions to the basic model

$$
  y_i \sim Poisson(\lambda) \\
  \lambda \sim \Gamma(\alpha, \beta)\\

  \lambda | Y \sim \Gamma(\alpha + \sum^n_{i=0}y_i, \beta + n)
$$

```{r}


sample_closed_draws <- function(samples, n_draws, alpha = 0.001, beta = 0.001) {
  n <- length(samples)
  closed_draws <- rgamma(n_draws, alpha + sum(samples), beta + n)  
  return(data.frame(lambda=closed_draws))
}
close_main_draws <- sample_closed_draws(main_df$Citation, 4000)
close_main_draws$venue <- "main"
close_find_draws <- sample_closed_draws(findings_df$Citation, 4000)
close_find_draws$venue <- "findings"

plotting_data <- rbind(close_main_draws, close_find_draws)
ggplot(plotting_data, aes(lambda, color=venue, fill=venue)) +
  geom_histogram(bins=100, alpha=.5) +
  theme(legend.position="top") +
  geom_vline(aes(xintercept=mean(close_main_draws$lambda)), linetype="dashed", size=.5) + 
  geom_vline(aes(xintercept=mean(close_find_draws$lambda)), linetype="dashed", size=.5)
```

investigate diff and the "probability" of there being overlap between the predictive posterior distribution
```{r}
main_prediction_posterior <- sapply(close_main_draws$lambda, function(lambda) rpois(1, lambda))
findings_prediction_posterior <- sapply(close_find_draws$lambda, function(lambda) rpois(1, lambda))
transformed_dist <- main_prediction_posterior - findings_prediction_posterior
predicted_mean <- mean(transformed_dist)
```

```{r}
a <- data.frame(lambda=main_prediction_posterior)
a$venue = "main"
b <- data.frame(lambda=findings_prediction_posterior)
b$venue = "findings"

ggplot(rbind(a,b), aes(lambda, color=venue, fill=venue)) +
  geom_density(alpha=.5) +
  labs(title="predictive posterior draws", x=TeX("\\tilde{y}"), y="")
```
```{r}
data <- rbind(main_df, findings_df)

truncate <- function(data_df, p, name, n_samples = 4000) {
  mask <- data_df$Citation < quantile(data_df$Citation, p)
  truncated_data_df <- data_df[mask, ]
  
  lambda_draws <- sample_closed_draws(truncated_data_df$Citation, n_samples)
  predictive_draws <- sapply(lambda_draws$lambda, function(lambda) rpois(1, lambda))
  ys <- data.frame(Citation=predictive_draws)
  ys$Journal <- name
  
  return(ys)
}

threshold <- .75
tmp_main_df <- truncate(main_df, threshold, "predictive_main(truncated)")
tmp_find_df <- truncate(findings_df, threshold, "predictive_findings(truncated)")
tmp_df <- rbind(tmp_main_df, tmp_find_df)

tmp = data.frame(Citation=data$Citation, Journal=data$journal)
tmp = rbind(tmp, tmp_df)

ggplot(tmp, aes(Citation, color=Journal, fill=Journal)) +
  geom_density(alpha=0.2) +
  coord_cartesian(xlim=c(0, 50))


```




```{r}
ggplot(data.frame(y_hat = transformed_dist), aes(y_hat)) +
  geom_histogram(bins=35, color="black", fill="lightblue", alpha=.6) + 
  geom_vline(aes(xintercept=mean(predicted_mean)), linetype="dashed", size=.5) +
  labs(title="", x=TeX("\\tilde{y}_m - \\tilde{y}_f"), y="") +
  annotate("text", x=10, y=250, label= paste("mean =", round(predicted_mean, 2)))
P <- ecdf(transformed_dist)
eps <- 1
P(0+eps)-P(0-eps)
```

$$
P(|y_m - y_f| \leq 1) = 0.16
$$

# Creating the model

```{r}
# processed data
sizes <- c(nrow(main_df), nrow(findings_df))
data <- rbind(main_df, findings_df)$Citation
sizes
# data
```

```{r}
get_weakly_informative_gamma = function(samples) {
  alpha_est = mean(samples)^2 / (max(samples) - min(samples));
  beta_est = alpha_est / mean(samples);
  
  return(c(alpha_est, beta_est));
}

get_weakly_informative_normal = function(samples_short, samples_long) {
  eps = 1e-12
  lower = min(min(samples_short + eps) / max(samples_long), min(samples_long + eps) / max(samples_short))
  upper = max(samples_long) / mean(samples_short)
  mu = mean(samples_long) / mean(samples_short)
  sigma = (upper - mu) / 2.576
  
  return(c(mu, sigma));
}



get_weakly_informative_gamma(main_df$Citation)
get_weakly_informative_gamma(findings_df$Citation)
```



```{r}
model_data <- list(N = length(data),
                   sizes = sizes,
                   J = 2,
                   y = data,
                   K = 3,
                   alpha=c(4, 1, 1))

fit <- stan(file = "model_mixture.stan", 
            data = model_data,
            chains = 4,
            iter = 3000,
            warmup = 2000)
fit
```



```{r}
draws <- as.data.frame(fit)
apply(array, margin, ...)
```


## posterior predictive draws

```{r}
draws <- as.data.frame(fit)
yrep <- extract(fit, permuted=FALSE)
dimnames(yrep)

y_main <- main_df$Citation
y_findings <- findings_df$Citation
yrep_main <- matrix(yrep[,,3], nrow=4, ncol=length(y_main))
yrep_findings <- matrix(yrep[,,4], nrow=4, ncol=length(y_findings))

print(length(y_main))
color_scheme_set("viridis")
ppc_dens_overlay(y_main, yrep_main) + ggtitle('Main') + xlim(0,100) + yaxis_text() + theme(text = element_text(size = 16, family="sans"))     
ppc_dens_overlay(y_findings, yrep_findings) + ggtitle('Findings') + xlim(0,100)  + yaxis_text() + theme(text = element_text(size = 16, family="sans"))   
```

