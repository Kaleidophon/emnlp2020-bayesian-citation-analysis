---
title: "project"
author: "anon"
date: "11/22/2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(aaltobda)
library(rstan)
library(loo)
rstan_options (javascript = FALSE)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

# Modeling the data 

In the following, we describe the model used for our experiments. 
We posses a dataset of papers from two EMNLP 2020 venues: Main conference and findings,
which are indicated when necessary with indices $m$ and $f$, respectively (where possible, we omit these for readability). 
For each venue, have $N$ total observations, with two features $y_i^{(1)}$ and $y_i^{(2)}$ each.

The first one denotes the number of citations, which we model using a Poisson distribution and a Gamma prior:

$$ 
y_i^{(1)} \sim \text{Poisson}(\lambda)\\
\lambda \sim \Gamma(\alpha_\lambda, \beta_\lambda)
$$
The second one described whether paper is a short or a long paper, which we model using a Bernoulli with a Beta prior:

$$
y_i^{(2)} \sim \text{Bernoulli}(\rho) \\
\rho \sim \text{B}(\alpha_\rho, \beta_\rho)
$$
This leads us to the following likelihood and posterior for a single sample (TODO: Here we might want to introduce a dependency between paper length and citations):

$$
  p(y_i|\lambda, \rho) = p(y_i^{(1)}|\lambda)p(y_i^{(2)}|\rho)\\
$$

Further, we can formulate the following posterior for the entire Dataset $\mathbb{D} = \{y_1, \ldots, y_N\}$:
$$
  p(\lambda, \rho|\mathbb{D}, \theta) \propto \prod_{i=1}^N p(y_i^{(1)}|\lambda)p(\lambda|\alpha_\lambda, \beta_\lambda)p(y_i^{(2)}|\rho)p(\rho|\alpha_\rho, \beta_\rho)
$$
where we summarize all hyperparameters as $\theta = [\alpha_\lambda, \beta_\lambda, \alpha_\rho, \beta_\rho]$ to avoid clutter. As we see in the the next section, we would actually like to reason about the posterior $p(\lambda, \rho|\mathbb{D})$. 
We could do that for instance by integration:

$$
  p(\lambda|\mathbb{D}, \theta) = \int p(\lambda, \rho|\mathbb{D}, \theta) d\rho
$$

[//]: # "Since we chose conjugate prior for the two feature likelihoods and assumed the features to be independent, we know that the posterior $p(\lambda, \rho|\mathbb{D})$ is a product of a Beta with posterior parameters $\alpha_\rho + \sum_{i=1}^N y^{(2)}_i, \beta_\rho + N - \sum_{i=1}^N y^{(2)}_i$ and a Gamma with posterior parameters $\alpha_\lambda + \sum_{i=1}^N y^{(1)}_i, \beta_\lambda + N$ (see for instance [Wikipedia](https://en.wikipedia.org/wiki/Conjugate_prior) for this standard result)."

We avoid analytical integration of this expression and instead evaluate the integral using $M$ Monte Carlo samples from the Binomial posterior. We can do this either using samples that were collected using MCMC, or sampling from the Beta posterior directly, since we know its parameters via conjugacy, namely $\alpha_\rho + \sum_{i=1}^N y^{(2)}_i, \beta_\rho + N - \sum_{i=1}^N y^{(2)}_i$:

$$
  p(\lambda|\mathbb{D}, \theta) = \int p(\lambda, \rho|\mathbb{D}, \theta) d\rho \approx \frac{1}{M}\sum_{j=1}^M p(\lambda, \rho_j|\mathbb{D}, \theta);\quad \rho_j \sim p(\rho|\mathbb{D}, \alpha_\rho, \beta_\rho)
$$
# Research question

We are interested in finding out whether publishing at the main conference or finding has an impact on one's citations. 
For this purpose, we would like to compare the posterior distributions $p(\lambda_m|\rho_m, \mathbb{D}_m) \stackrel{?}{=} p(\lambda_f|\rho_f, \mathbb{D}_f)$. 
Since $\lambda_m, \lambda_f$ can in this context be interpreted as the mean citation rates for both venues, comparing their respective posterior distributions allows us to answer this question given the data and taking uncertainty into account.

# Using a hierarchical model

We can choose to model the distributions of interest - $p(\lambda_m|\rho_m, \mathbb{D}_m)$ and $p(\lambda_f|\rho_f, \mathbb{D}_f)$ - each with their separate priors. However, we also consider a shared hyperprior for the respective $\lambda$ and $\rho$ parameters. Intuitively, this implies that we either assume our prior belief about the citation rate of papers at both venues to be the same OR the range of probabilities to be a long or short paper at both venues to be similar. The generative stories of such hierarchical models is given below. 

Shared hyperprior for $\lambda$:
$$
\lambda_m, \lambda_f \sim \Gamma(\alpha_0, \beta_0)\\
\rho_m \sim \text{B}(\alpha_{\rho_m}, \beta_{\rho_m})\\
\rho_f \sim \text{B}(\alpha_{\rho_f}, \beta_{\rho_f})\\
$$
Shared hyperprior for $\rho$:

$$
\lambda_m \sim \Gamma(\alpha_m, \beta_m)\\
\lambda_f \sim \Gamma(\alpha_f, \beta_f)\\
\rho_m, \rho_f \sim \text{B}(\alpha_0, \beta_0)\\
$$

# R and Stan Code


```{r}
list.files()
```

```{r}
findings_df <- read.csv("findings.tsv_type.csv")
findings_df$journal = "findings"
head(findings_df)

main_df <- read.csv("main.tsv_type.csv")
main_df$journal = "main"
head(main_df)
```

```{r}
dim(main_df)
dim(findings_df)
data <- rbind(main_df, findings_df)
```

```{r}
# processed data
sample_size <- min(dim(main_df)[1], dim(findings_df)[1])
main_citations <- sample(main_df$Citation, size = sample_size)
findings_citations <- sample(findings_df$Citation, size = sample_size)
processed_data <- cbind(main_citations, findings_citations)
```


```{r}
model_data <- list(N = nrow(processed_data),
                   J = ncol(processed_data),
                   y = processed_data)

fit <- stan(file = "model.stan", 
            data = model_data,
            chains = 2,
            iter = 2000,
            warmup = 1000)
```

```{r}
draws <- as.data.frame(fit)
draws
ggplot(draws, aes(`lambda[1]`)) + geom_histogram(bins=30)
ggplot(draws, aes(`lambda[2]`)) + geom_histogram(bins=30)
```


```{r}
findings_citations <- sample(findings_df$Citation, size = 447, replace = T)
main_citations <- sample(main_df$Citation, size = 447, replace = T)

citation_pairs <- cbind(main_citations, findings_citations)
colMeans(citation_pairs)
```
